# -*- coding: utf-8 -*-
"""cnn3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SViHKCXELzz5PDu_znK6qyKnuZRfdTHf
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set(style="whitegrid")
import os
import glob as gb
import cv2
import tensorflow as tf
import keras

from google.colab import drive
drive.mount('/content/drive')

### path dir in gdrive
trainpath ='/content/drive/My Drive/new_test/ttttt/tomato/New Plant Diseases Dataset(Augmented)/'
testpath = '/content/drive/My Drive/new_test/ttttt/tomato/New Plant Diseases Dataset(Augmented)/'
predpath = '/content/drive/My Drive/new_test/ttttt/testcnn'
#catago=["Tomato___Bacterial_spot","Tomato___Early_blight","Tomato___Late_blight","Tomato___Leaf_Mold","Tomato___Septoria_leaf_spot","Tomato___Spider_mites Two-spotted_spider_mite","Tomato___Target_Spot","Tomato___Tomato_Yellow_Leaf_Curl_Virus","Tomato___Tomato_mosaic_virus","Tomato___healthy"]

#first check the Train folder to have a look to its content

for folder in  os.listdir(trainpath + 'train') : 
    files = os.listdir(os.path.join(trainpath +'train/' + folder ))
    print(f'For training data , found {len(files)} in folder {folder}')

#check the Train folder to have a look to its content
for folder in  os.listdir(trainpath + 'valid') : 
    files = os.listdir(os.path.join(trainpath +'valid/' + folder ))
    print(f'For testing data , found {len(files)} in folder {folder}')

#check the pred folder to have a look to its content
files = os.listdir(predpath)
print(f'For Prediction data , found {len(files)}')

#Checking Images
#now we need to heck the images sizes , to know ow they looks like

#code = {'buildings':0 ,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}
code={"Tomato___Bacterial_spot":0,"Tomato___Early_blight":1,"Tomato___Late_blight":2,"Tomato___Leaf_Mold":3,"Tomato___Septoria_leaf_spot":4,"Tomato___Spider_mites Two-spotted_spider_mite":5,"Tomato___Target_Spot":6,"Tomato___Tomato_Yellow_Leaf_Curl_Virus":7,"Tomato___Tomato_mosaic_virus":8,"Tomato___healthy":9}


def getcode(n) : 
    for x , y in code.items() : 
        if n == y : 
            return x

#images sizes in train folder
size = []
for folder in  os.listdir(trainpath +'train') : 
    files = os.listdir(os.path.join( trainpath +'train/' + folder ))
    for file in files[0:300]:
        fille=os.path.join(os.path.join( trainpath +'train/' + folder )+'/'+file)
        image = plt.imread(fille)
        size.append(image.shape)
pd.Series(size).value_counts()
print(size)

#images test in train folder
size = []
for folder in  os.listdir(trainpath +'valid') : 
    files = os.listdir(os.path.join( trainpath +'valid/' + folder ))
    for file in files[0:30]:
        fille=os.path.join(os.path.join( trainpath +'valid/' + folder )+'/'+file)
        image = plt.imread(fille)
        size.append(image.shape)
pd.Series(size).value_counts()

#images sizes in pred folder
size = []
files = os.listdir(predpath )
for file in files:
    fille=os.path.join(predpath,file) 
    image = plt.imread(fille)
    size.append(image.shape)
pd.Series(size).value_counts()

#Reading Images
#now it's time to read all images & convert it into arrays

#read all pictues in ten categories in training folder, ans use OpenCV to resize it 

s = 256

X_train = []
y_train = []
for folder in  os.listdir(os.path.join(trainpath+'train')) : 
    files = os.path.join(trainpath+'train/'+folder )
    for file in os.listdir(files)[0:1000]: 
        fille=os.path.join(os.path.join( trainpath +'train/' + folder )+'/'+file)
        image = cv2.imread(fille)
        image_array =cv2.resize(image , (s,s))
        X_train.append(list(image_array))
        y_train.append(code[folder])

print(f'we have {len(X_train)} items in X_train')           #how many items in X_train

# look to random pictures in X_train , and to adjust their title using the y value

plt.figure(figsize=(20,20))
for n , i in enumerate(list(np.random.randint(0,len(X_train),36))) : 
    plt.subplot(6,6,n+1)
    plt.imshow(X_train[i])   
    plt.axis('off')
    plt.title(getcode(y_train[i]))

#read all pictues in ten categories in testing folder, ans use OpenCV to resize it

X_test = []
y_test = []
for folder in  os.listdir(os.path.join(testpath+'valid')) : 
    files = os.path.join(testpath+'valid/'+folder )
    for file in os.listdir(files)[0:350]: 
        fille=os.path.join(os.path.join( trainpath +'valid/' + folder )+'/'+file)
        image = cv2.imread(fille)
        image_array = cv2.resize(image ,(s,s))
        X_test.append(list(image_array))
        y_test.append(code[folder])

#how many items in X_test
print(f'we have {len(X_test)} items in X_test')

#Verify the test data
#To verify that the dataset looks correct, let's plot  36 images from
 #the training set and display the class name below each image.

plt.figure(figsize=(20,20))
for n , i in enumerate(list(np.random.randint(0,len(X_test),36))) : 
    plt.subplot(6,6,n+1)
    plt.imshow(X_test[i])    
    plt.axis('off')
    plt.title(getcode(y_test[i]))

X_pred = []
files =os.listdir(predpath)
for file in files[0:500]:
    fille=os.path.join(predpath,file)
    image = cv2.imread(fille)
    image_array = cv2.resize(image ,(s,s))
    X_pred.append(list(image_array))

print(f'we have {len(X_pred)} items in X_pred')              #how many item in x_pred

plt.figure(figsize=(20,20))
for n , i in enumerate(list(np.random.randint(0,len(X_pred),36))) : 
    plt.subplot(6,6,n+1)
    plt.imshow(X_pred[i])    
    plt.axis('off')

# convert the data into arrays using numpy

X_train = np.array(X_train)
X_test = np.array(X_test)
X_pred_array = np.array(X_pred)
y_train = np.array(y_train)
y_test = np.array(y_test)

print(f'X_train shape  is {X_train.shape}')
print(f'X_test shape  is {X_test.shape}')
print(f'X_pred shape  is {X_pred_array.shape}')
print(f'y_train shape  is {y_train.shape}')
print(f'y_test shape  is {y_test.shape}')

X_train=X_train/255.0
X_test=X_test/255.0

##Building The Model
#Create the convolutional base

KerasModel = keras.models.Sequential([
        keras.layers.Conv2D(224,kernel_size=(3,3),padding='same',activation='relu',input_shape=(s,s,3)),
       
        keras.layers.Conv2D(200,kernel_size=(3,3),padding='same',activation='relu'),
        
        keras.layers.MaxPool2D(4,4),
      ## keras.layers.BatchNormalization(),
        keras.layers.Conv2D(198,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(196,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(196,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),

         keras.layers.Conv2D(194,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(192,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(190,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),

         keras.layers.Conv2D(180,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(160,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(150,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(140,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(130,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(130,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(120,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(110,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(100,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(90,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         ## keras.layers.BatchNormalization(),   
        keras.layers.Conv2D(80,kernel_size=(3,3),padding='same',activation='relu'),
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(70,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         keras.layers.Conv2D(60,kernel_size=(3,3),padding='same',activation='relu'), 
         keras.layers.MaxPool2D(4,4),
         
         ##keras.layers.BatchNormalization(),   
        keras.layers.Conv2D(50,kernel_size=(3,3),padding='same',activation='relu'),
        
        keras.layers.MaxPool2D(4,4),
       # #keras.layers.BatchNormalization(),
       
        keras.layers.Flatten() ,    
        keras.layers.Dense(120,activation='relu') ,
         keras.layers.Dropout(rate=0.3),  
        keras.layers.Dense(100,activation='relu') , 
         
        keras.layers.Dense(50,activation='relu') ,        
        keras.layers.Dropout(rate=0.3) ,
        keras.layers.Dense(10,activation='softmax')   
        ])

#Compile and train the model
#display the architecture of our model so far

KerasModel.compile(optimizer ='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

print('Model Details are : ')
print(KerasModel.summary())

##training the model with 45epochs  #

epochs = 45
ThisModel = KerasModel.fit(X_train, y_train, epochs=epochs,batch_size=32,verbose=1)

ModelLoss, ModelAccuracy = KerasModel.evaluate(X_test, y_test)

print('Test Loss is {}'.format(ModelLoss))
print('Test Accuracy is {}'.format(ModelAccuracy ))

#predict X test

y_pred = KerasModel.predict(X_test)

print('Prediction Shape is {}'.format(y_pred.shape))

#predict X X Predic

y_result = KerasModel.predict(X_pred_array)

print('Prediction Shape is {}'.format(y_result.shape))

plt.figure(figsize=(20,20))
for n , i in enumerate(list(np.random.randint(0,len(X_pred),20))) : 
    plt.subplot(6,6,n+1)
    plt.imshow(X_pred[i])    
    plt.axis('off')
    plt.title(getcode(np.argmax(y_result[i])))

